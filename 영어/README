영어감정분석
모델 및 각종 아이디어의 경우 오픈되어 있는 소스를 참고했습니다.(아래 링크 첨부 참고)

정보
frineds_train, frined_dev 를 train set으로 frineds_test 를 test set 으로 설정했습니다. 
각 데이터셋의 경우 발화(utterance) (최대길이 = maxlen) 와 그에 해당하는 감정 라벨이 주어집니다. 
각 감정라벨에 해당하는 인덱스는 아래에 소개됩니다.

요구
- numpy
- pandas
- matplotlib
- nltk
- keras with TensorFlow backend
- transformers (for BERT model)
- torch (for BERT model)

사용
실행환경은 colab 을 사용하였으며, 따라서 해당 코드를 colab 에서 아래 순서 그대로 실행시켜 주시면 됩니다.

필요한 package 모두 import
json 파일 읽은 후, 3파일 모두 cleaning 함수를 통해 아래 과정 진행 후 train, dev는 train_data에 저장 test는 test_data에 저장
영어 이외 data re 패키지를 이용해 제거
소문자로 모두 통일
nltk 의 stopwords를 이용해 불용어 제거
nltk 의 stemmer를 이용해 stemming
구해진 문장을 bert tokenizer를 사용해 토큰으로 분리하기 위해, 문장 편집 (앞에 [CLS] , 뒤에 [SEP] 을 달아줍니다. cls : classification , sep : 문장 구분) 후, token으로 분리
3번에서 구해진 token을 숫자 값으로 indexing 하고, maxlen을 이용해 padding 진행, 그리고 attention_masks를 설정 (데이터가 >0 인 단어부분에 attention을 주어서 학습 속도와 성능을 향상시킵니다.)
labeltoint 함수를 생성해 labels에 train_data의 label을 저장, 학습을 위해 torch tensor 형태로 모든 데이터들을 변환해줍니다.
cell3~cell5에 해당하는 과정을 test_data에 대해서도 진행해줍니다.
GPU 사용가능 여부를 확인(colab의 경우 가능) 후, pretrained 된 모델을 model에 불러오고, optimizer와 각종 파라미터, scheduler들을 세팅
training 진행
kaggle 데이터를 불러온 후 제출을 위해 dataframe 생성하는 부분
실제 문장 확인하는 구문 predict('') 안의 내용을 원하는 문장으로 바꿔주면 됩니다.

참조
https://myjamong.tistory.com/77
http://aidev.co.kr/chatbotdeeplearning/8709
https://neurowhai.tistory.com/294
