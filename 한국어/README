한글감정분석
모델 및 각종 아이디어의 경우 오픈되어 있는 소스를 참고했습니다.(아래 링크 첨부 참고)

정보
ratings_train.txt를 train set으로 ratings_test.txt를 test set 으로 설정했습니다. 
각 파일은 id, document, label의 세 열로 구성됩니다.
- id: 네이버에서 제공 한 리뷰 아이디
- document: 실제 리뷰
- label: 리뷰의 감정 클래스입니다. (0 : 부정, 1 : 긍정적)
열은 탭으로 구분됩니다 (예 : .tsv 형식이지만 파일 확장자는 초보자가 쉽게 액세스 할 수 있도록 .txt 임).

요구
- tensorflow
- torch
- transformers
- keras
- pandas
- numpy
- random
- time
- datetime
- collections
- glob
- os
- re
- lxml
- requests

사용
실행환경은 colab 을 사용하였으며, 따라서 해당 코드를 colab 에서 아래 순서 그대로 실행시켜 주시면 됩니다.

필요한 package 모두 import
txt 파일 읽은 후, 모두 cleaning 함수를 통해 아래 과정 진행 후 ratings_train는 train_data에 저장 ratings_test는 test_data에 저장
구해진 문장을 bert tokenizer를 사용해 토큰으로 분리하기 위해, 문장 편집 (앞에 [CLS] , 뒤에 [SEP] 을 달아줍니다. cls : classification , sep : 문장 구분) 후, token으로 분리
3번에서 구해진 token을 숫자 값으로 indexing 하고, maxlen을 이용해 padding 진행, 그리고 attention_masks를 설정 (데이터가 >0 인 단어부분에 attention을 주어서 학습 속도와 성능을 향상시킵니다.)
labeltoint 함수를 생성해 labels에 train_data의 label을 저장, 학습을 위해 torch tensor 형태로 모든 데이터들을 변환해줍니다.
cell3~cell5에 해당하는 과정을 test_data에 대해서도 진행해줍니다.
GPU 사용가능 여부를 확인(colab의 경우 가능) 후, pretrained 된 모델을 model에 불러오고, optimizer와 각종 파라미터, scheduler들을 세팅
training 진행
kaggle 데이터를 불러온 후 제출을 위해 dataframe 생성하는 부분
실제 문장 확인하는 구문 predict('') 안의 내용을 원하는 문장으로 바꿔주면 됩니다.

참조
http://aidev.co.kr/chatbotdeeplearning/8709
http://yonghee.io/bert_binary_classification_naver/


